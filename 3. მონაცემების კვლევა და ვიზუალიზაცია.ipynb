{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. მონაცემების კველვა და ვიზუალიზაცია"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "პირველი თავის ბოლოს ჩვენ ორი შედარებით მარტივი მოდელი ავაგეთ და ვნახეთ თუ რამდენად დახვეწილია დღეს მანქანური დასწავლის ბიბლიოთეკები. თუმცა აღნიშნული მაგალითები იყო საილუსტრაციო ხასიათის. ჩვენ გამოვტოვეთ მონაცემებზე დაფუძნებული ამოცანების ერთ-ერთი ყველაზე მნიშნველოვანი ნაწილი, მონაცემების კვლევა. ეს თავი სწორადაც რომ აღწერითი და დიაგნოზსტიკური ანალიზების ნაზავზე იქნება ორიენტირებული, რასაც მონაცემთა მეცნიერებაში მონაცემების კვლევით ანალიზს (Exploratory Data Analysis, შემოკლებულად-EDA) უწოდებენ.\n",
    "\n",
    "აღნიშნული პროცესის განუყოფელი ნაწილია, მონაცემების ვიზუალიზაცია, შესაბამისად ამ თავში ასევე დავფარავთ ვიზუალიზაციის ყველაზე გავრცელებულ და ხშირად გამოყენებად ნაწილებს. რა თქმა უნდა პითონში არებობს მრავალი ძალიან დახვეწილი და მრავალფუნქციური ვიზუალიზაციის ბიბლიოთეკა, რომელთა მეშვებითაც თითქმის ყველაფერს შეძლებთ რასაც მოისურვებთ. თუმცა მონაცემთა ვიზუალიზაცია ცალკდე დიდი დარგია რაც ცხდება წიგნის მიზნებს. სწორად ამიტომ მხოლოდ მარტივ ხერხებს მივმართავთ, რაც მონაცემების სწრაფად აღქმასა და გაანლიზებაში დაგვეხმარება. \n",
    "\n",
    "მონაცვლეობით გამოვიყენებთ, როგორც pandas-ის ჩაშენებულ ფუნქციებს ისე ერთ-ერთ ყველაზე გავრცელებულ, სწრაფ და მოქნილ Seaborn-ის ბიბლიოთეკას. ასევე აღსანიშნავია პითონის ვიზუალიზაციის მთვარი ბიბლიოთება-matplotlib, რომელზეც არის დაშენებული seaborn. როგორც წესი ის პითონის ყველა ვერსიას მოყვება და არ საჭიროებს დაყენებას, თუმცა იგივეს ვერ ვიტყვით seaborn-ზე ამიტომ შესაძლოა მისი დაინსტალირებაც დაგვჭირდეს.\n",
    "\n",
    "იმისათვის რომ მონაცემთა კვლევის ყველა ნაბიჯი დეტალურად დავფაროთ, ამ თავში ჩვენ მხოლოდ ერთ ცხრილს გამოვიყენებთ -  ნიუ იორკის ტაქსით მგზავრობის ხანგრძილოვებების შსახებ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 სამუშაო გარემოს მოწყობა და მონაცემების შემოტანა\n",
    "\n",
    "მიღებულია, რომ ნებისმიერი მანქანური დასწავლის სამუშაო იწყება ყველა საჭირო ბიბლიოთეკისა და მონაცემების სამუშაო გარემოში შემოტანით. ჩვენც შესაბამისად მოვიქცეთ და გავმართოთ სამუშაო გარემო შემდეგი ბრძანებების გამოყენებით:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn #აღნიშნული ბრძანება საჭიროა მხოლოდ იმ შემთხვევაში, თუ თქვენ უკვე არ გაქვთ დაყენებული\n",
    "                     # seaborn-ის ბიბლიოთეკა.\n",
    "#ზოგადად ბრძანება რომელიც იწყება !pip install განკუთვნილია კონკრეტული ბიბლიოთეკის დასაყენებლად, შესაბამისი \n",
    "#სახელის მითითებით."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #მონაცემების დამუშავების ბიბლიოთეკა\n",
    "import numpy as np #მონაცემების დამუშავების ბიბლიოთეკა\n",
    "import seaborn as sns #მონაცემების ვიზუალიზაციის ბიბლიოთეკა\n",
    "import matplotlib.pyplot as plt #მონაცემების ვიზუალიზაციის ბიბლიოთეკა\n",
    "\n",
    "# წინასწარ განსაზღვრულად matplotlib ბიბლიოთეკა, არ ბეჭდავს ვიზუალიზაციას დამატებითი, .show(), ბრძანების გარეშე,\n",
    "# თუმცა ქვემოთ მოცემული კოდი დაგვეხმარება არსებულ ნოუთბუქში, ვიზუალიზაციის ნებისმიერი ფუნქციის გამოყენების\n",
    "# შემდგომ, პირდაპირ დავბეჭდოთ გრაფიკები\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!ln -s /content/gdrive/My\\ Drive/ /mydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mydrive/DS101 - Call II/S5-6 EDA and Visualization/NYCTaxi.csv') #მთლიანი მონაცემების შემოტანა სამუშაო გარემოში"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 მონაცემების პირველადი კვლევა"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "სანამ უშუალოდ მონაცემების შესწავლაზე გადავალთ, როგორც პირველ თავში აღვნიშნეთ ნებისმიერი მონაცემებზე დაფუძნებული ამოცანა მისი შინაარსის გააზრებით იწყება. სწორად ამიტომ ჯერ კარგად აღვწეროთ საერთოდ რა ტიპის მონაცემებთან გვექნება საქმე და რა მიზანს ისახავს.\n",
    "\n",
    "მოცემული გვაქვს 2016 წლის ნიუ იორკის \"ყვითელი ტაქსებით\" მგზავრობის მონაცემები შემდეგი ცვლადებით:\n",
    "* id - ჩანაწერის უნიკალური ნომერი\n",
    "* vendor_id - ტაქსის პროვაიდერის ნომერი\n",
    "* pickup_datetime - მგზავრობის დაწყების დრო\n",
    "* dropoff_datetime - მგზავრობის დასრულების დრო\n",
    "* passenger_count - მგზავრების რაოდენობა\n",
    "* pickup_longitude - მგზავრობის დაწყების გრძედი\n",
    "* pickup_latitude - მგზავრობის დაწყების განედი\n",
    "* dropoff_longitude - მგზავრობის დასრულების გრძედი\n",
    "* dropoff_latitude - მგზავრობის დასრულების განედი\n",
    "* store_and_fwd_flag - Y და N-ით აღნიშნულია მანქანამ პირდაპირ გადასცა მგზავრობის ინფორმაცია სერვერს, თუ ვერ დაუკავშირდა და ჯერ ლოკალურად შეინახა.\n",
    "* trip_duration - მგზავრობის ხანგრძლივობა წამებში.\n",
    "\n",
    "ამოცანის მიზანია მოცემული ცვლადების გამოყენებით (გარდა dropoff_datetime-სა) ავაგოთ ისეთი მოდელი, რომელიც იპროგნოზებს მგზავრობის ხანგძლივობას (trip_duration). ჩვენ ამ თავში მოდელს არ ავაგებთ და მხოლოდ მონაცემების კვლევით შემოვიფარგლებით. შინაარსობრივადაც რთული ამოცანა ნამდვილად არ არის, ამიტომ შეგვიძლია პირდაპირ საქმეზე გადავიდეთ.\n",
    "\n",
    "*ამოცანის და მონაცემების დეტალური აღწერისთვის, გირჩევთ ეწვიოთ წყაროს:* https://www.kaggle.com/competitions/nyc-taxi-trip-duration/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape #მონაცემების განზომილებების შემოწმება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() #მონაცემების პირველი 5 ჩანაწერის დაბეჭვდა"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #მონაცემების ტიპების შემოწმება"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".info() ბრძანების დახმარებით ვხედავთ, რომ თარიღებთან დაკავშირებული ორივე ცვლადი ობიექტის ტიპად არის ჩაწერილი. ხოლო მათ მოქნილად და სწრაფად დასამუშავებლად აუცილებელია ისინი გადავიყვანოთ datetime  ფორმატში."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "მანქანური დასწავლის არც ერთი მოდელი არ მუშაობს ცარიელ მონაცემებთან. შესაბამისად საჭიროა მათი შემოწმება და გარკვეული მონაცემებით შევსება ან სულაც ასეთი ცვლადების წაშლა. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentages = df.isna().sum().sort_values(ascending = True) / len(df)\n",
    "missing_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "მოდით დეტალურად ავხსნათ თუ როგორ მუშაობს ზემოთ მოყვანილი ბრძანება. df.isna() ყველა ჩანაწერისთვის აბრუნებს  True/False მნიშნვნელობებს, ხოლო როგორც წინა თავში გავიარეთ პითონი ბულიან ცვლადებს 1/0-ებად აღიქვამს. შესაბამისად როდესაც df.isna().sum() ვბეჭადვს ის უბრალოდ ყველა True-ს აჯამებს, რაც თითეულ ცვლადში ცარიელი მნიშნველობების რაოდენობას გამოიტანს. შემდგომი ბრძანება .sort_values(ascending = True) მონაცემებს უბრალოდ ზრდადობით ალაგებს. ხოლო მთლიანი ცხრილის სიგრძეზე გაყოფა (/len(df)), ცარიელი მონაცემების პროცენტულ მნიშნველობებს გვიბრუნებს.\n",
    "\n",
    "გაგვიმართლა, რომ ყველა ცვლადი შევსებულია და არ გვიწევს ამ პრობლემაზე ზრუვნა. თუმცა რეალურ გარემოშო უფრო ხშირად შეხვდებით ისეთ მონაცემებს, სადაც რამდენიმე ცვლად ჩანაწერები აკლია. თუ უნდა მოვეპყროთ ცარიელ მონაცემებს, ამაზე დეტალურად ვისაუბრებთ მომდევნო თავებში.\n",
    "\n",
    "ახლა კი შეგვიძლია pandas ბიბლიოთეკის ერთ-ერთი ყველაზე მნიშნველოვანი და გენილური ფუნქცია .describe() გამოვიყენოთ. აღნიშნული ფუნქცია ყველა გადაცემულ რიცხვით ცვლადზე აბრუნებს აღწერითი სტატისტიკის შემდეგ მახასიათებლებს:\n",
    "* count - ჩანაწერების რაოდენობა\n",
    "* mean - ცვლადის არითმეტიკული საშუალო\n",
    "* std - ცვლადის სტანდარტული გადახრა\n",
    "* min - ცვლადის მინიმალური მნიშვნელობა\n",
    "* 25% - ცვლადის 25-ე პერსენტილი\n",
    "* 50% - ცვლადის 50-ე პერსენტილი, ანუ მედიანა\n",
    "* 75% - ცვლადის 75-ე პერსენტილი\n",
    "* max - ცვლადის მაქსიმალური მნიშვნელობა\n",
    "\n",
    "მიუხედავად იმისა, რომ ჩვენ მონაცემებში მრავალი რიცხვითი მნიშვნელობების მქონე ცვლადია, შინაარსობრივად გრძედის და განედის აღწერითი სტატისტიკური მახასიათებლები აზრს მოკლებულია. შესაძლოა რაიმე მინიშნება მოგვცეს განცალკევებულ მონაცემებზე, მაგალითად თუ მინიმალური ან მაქსიმალური გრძედის მნიშვნელობა მკვეთრად განსხვავდება მისი საშუალოსა და სხვა მახასიათებლებისგან, თუმცა უმჯობესია ამით არ ვიხელმძღვანელოთ. ტაქსის პროვაიდერის ნომერიც რიცხვითი მნიშნველობაა, თუმცა ეს ცალსახად კატეგორიული ცვლადია და აქაც ბევრ დასვკებს ვერ გამოვიტანთ ზემოთ მოყვანილი მახასიათებლებით. შესაბამისად გამოდის, რომ მხოლოდ მგზავრების რაოდენობასა და მგზავრობის ხანგრძლიოვბაზე აქვს აზრი pandas-ის .describe() ფუნქციის გამოყენებას. თუმცა ჩვენ მაინც მთლიანი ცხრილი გადავცეთ და ვნახოთ რა შედეგებს მივიღებთ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.describe(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "პირველი რაც თვალში გვხდება მგზავრობის ხანგრძილოვბის მაქსიმალური მნიშნველობაა - 3,526,282 წამი, მიახლოებით 980 საათი. რა თქმა უნდა ეს მონაცემი რეალურს არ გავს. ძნელად წარმოსადგენია ვინმემ ტაქსით 40 დღე იმგზავროს. მეტად სავარაუდოდ საქმე გაფუჭებულ მონაცემთან გვაქვს. ასევე საყურადღეობა იმავე ცვლადის მინიმალური მნიშვნელობა - 1 წამი, რაც შესაძლოა გაუქმებულ შეკვეთას ნიშნავდეს. თუმცა ამ შემთხვევაში მგზავრობის დაწყებისა და დასრულების გრძედებიცა და განედებიც ერთამეთის ტოლი უნდა იყოს. მოკლედ რომ ვთქვათ მონაცემებზე ზოგადი წარმოდგენა უკვე შევიქმენით, ყველა ცვლადი გადავიყვანეთ მათთვის შესაბამის ფორმატში და ახლა უკვეა დროა თითოეული ცვლადის დეტალურ კვლევას შევუდგეთ. რადან პირველი ეჭვები მგზავრობის ხანგრძილოვბაზე გაგვიჩნა მოდით ამავე ცვლადით დავიწყოთ.\n",
    "\n",
    "რადგან მონაცემებსა და ამოცანა ზოგადი წარმოდგენა უკვე შევიქმენით, შეგვიძლია პირველი, საბაზისო, მოდელი ავაგოთ. შემდგომი თავის ბოლოს კი, როდესაც სრულად დავფარავთ მონაცემების კვლევასა და მათ დამუშავებას კიდევ ერთხელ ავაგდებთ და ვნახავთ თუ რა შედეგს იძლევა აღნიშნული ძალისხმევა.\n",
    "\n",
    "პირველი თავის მსგავსად ჩვენ ამჯერადაც autogluon-ს გამოვიყენებთ, ხოლო სიმარტივისთვის დროის ცვლადებს არ გამოვიყენებთ, რადგან ისინი დამუშავებას საჭიროებენ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ცვლადების დეტალური კვლევა"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 მგზავრობის ხანგრძლიოვბა\n",
    "\n",
    "მოდით პირველ რიგში აღნიშნული ცვლადის განაწილება დავბეჭდოთ და ვნახოთ გვაქვს თუ არა რაიმე ტიპის უცნაურობები.\n",
    "\n",
    "#####  ჰისტოგრამა\n",
    "ამისათვის ჰისტოგრამა გამოიყენება. მის ასაგებად, პირველ რიგში საჭიროა ცვლადის ტოლ ინტერვალებად დაყოფა და შემდეგ დათვლა თუ რამდენი მონაცემი ჩავარდა თითოეულ ინტერვალში (ბინში)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.distplot(df['trip_duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ზემოთ მოცემული განაწილებიდან, რთულია რაიმეს დანახვა. სავარაუდოდ ასეთი ვიზუალი სწორადაც განცალკევებული მონაცემების ბრალია. ან ჩანაწერების უმეტესობა მართლაც 0-თან ახლოსაა, თუმცა ამაზე პასუხი უკვე describe ფუნქციამ გაგვცა. ამიტომ შეგვიძლია მგაზვრობის ხანგღძლივობა ხელით მოვჭრათ, მაგალითად 2 საათზე და ასე ვცადოთ განაწილების შემოწმება."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.distplot(df[df['trip_duration'] < 7200]['trip_duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "საინტერესო იქნება შევამოწმოთ, ხომ არ განსხვავდება მგზავრობის ხანგრძლივობის განაწილება ტაქსის პროვაიდერების მიხედვით. ამისათვის ჯერ უნდა ვნახოთ რამდენი განსხვავებული კომპანიის ჩანაწერებია ჩვენს ცხრილში."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vendor_id'].nunique() #უნიკალური მნიშვნელობების რაოდენობის დაბეჭვდა"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vendor_id'].unique() #უნიკალური მნიშნვნელობიბის დაბეჭვდა"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.distplot(df[(df['vendor_id'] == 1) & (df['trip_duration'] < 7200)]['trip_duration'], bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.distplot(df[(df['vendor_id'] == 2) & (df['trip_duration'] < 7200)]['trip_duration'], bins = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ზემოთ მოცემული ორი განაწილება სხვადასხვა პროვაიდერებისთვის, პირველადი დაკვირვებით ერთგვაროვანია. თუმცა არ უნდა დაგვავიწყდეს, რომ ჩვენ მონაცემები 2 საათზე მოვჭერით. შესაბამისად შეგვიძლია ვთქვათ რომ \"ნორმალური\" ჩანაწერებისთვის განაწილებები ერთგვაროვანია, თუმცა რა ხდება განცალკევებულ ჩანაწერებზე? რომელიმე ერთ კომპანიაში ხომ არ არის უფრო მეტი ან ნაკლები? describe-ის შედეგერბიდან გამომდინარე უხეშად შეგვიძლია ვივარაუდოდ, რომ 2 საათზე მეტი ხანგრძლივობის ჩანაწერი საკმაოდ ცოტა იქნება. შესაბამისად შეგვიძლია უფრო მარტივი გზით წავიდეთ და ვნახოთ სულაც რამდენი ჩანაწერია 2 საათზე მეტი ხანგრძლივობის და როგორ ნაწილდება ეს სხვადახვა კოპმანიებზე."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['trip_duration'] >= 7200]['vendor_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "როგორც ვხედავთ სულ დაახლოებით 2500 ჩანაწერია 2 საათზე მეტი ხანგრძლივობის და აქედან 95%-ზე მეტი მეორე კომპანიაზე მოდის. აქ შესაძლოა ორ განსხვავებულ სცენართან გვქონდეს საქმე: 1. მეორე კომპანიიის მონაცემები უფრო მეტად არის დაიზიანებული ან სულაც სხვანაირად აღრიცხავენ ხანგრძლივობას; 2. რაღაც ისეთ მოშორებულ ლოკაციაზე დადის მეორე პროვაიდერი სადაც პირველი ან საერთოდ ან უფრო იშვიათან მიემგზავრება. თუმცა სანამ გეოგრაფიული ცვლადების გარჩევას დავიწყებთ, უმჯობესია ჯერ შედარებით მარტივი, მგზავრების რაოდენობის, ცვლადი გავაანალიზოთ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 მგზავრობის რაოდენობა\n",
    "\n",
    "##### Bar Chart\n",
    "ბარ ჩარტი არის გრაფიკი რომელიც გამოიყენება კატეგორიული მონაცემებისთვის და გადმოსცემს მის კატეგორიების მნიშვნელობებს სიმაღლეში ან სიგრძეში. შესაბამისად ის ძირითადად მონაცემების შესადარებლად აიგება. ხშირად კლებადობით დალაგებულ ჰორიზონტალურ ბარ ჩარტებს ანიჭებენ უპირატესობას, რადგან თვალისთვის სიგრძის შედარება უფრო მარტივია ვიდრე სიმაღლის. თუმცა ამ შემთხვევაში ჩვენ უფრო ზოგადი სურათის დანახვა გვსურს კომპანიების ჭრილში ხომ არ განსხვავდებიან მგზავრების რაოდენობით. \n",
    "\n",
    "იქედან გამომდინარე, რომ ტაქსიში მგზავრების რაოდენობა სავარაუდოდ 1-დან 4-მდე უნდა მერყეობდეს, value_counts ფუქნცია რთულად აღსაქმელ შედეგს მოგცემს და უმჯობესია seaborn ბიბლიოთეკის countplot გამოვიყენოთ, რომელიც თითეულ კატეგორიაში ჩანაწერების რაოდენობას სწორადაც რომ Bar Chart-ში გამოსახავს."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "sns.countplot(df[df['vendor_id'] == 1]['passenger_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "sns.countplot(df[df['vendor_id'] == 2]['passenger_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "როგორც ვხედავთ მეორე კომპანიას უფრო ხშირად გადაყავს მეტი მგზავრი, მეტიც ზოგ შემთხვევაში 5-ზე მეტი ადამიანის ტრანსპორტირებასაც კი უზრუნველყოფს. ეს სავარაუდოდ იმით აიხსნება, რომ მეორე კომპანიას სედანის ტიპის ავტომობილების გარდა მინი ვენებიც ყავს. აქვე შეგვიძლია ვივარაუდოთ, რომ მინი ვენით პროვაიდერი კლიენტებს მანჰეტენზე არ ემსახურება და სავაურადოდ აერპორტზე უფრო მეტად არის კონცენტრირებული. თუმცა ამ ვარაუდის დასადასტურებლად, ზემოთ მოყვანილი გრაფიკები ნამდვილად არ არის საკმარისი. შესაბამისად შეგვიძლია ეს ყველაფერი გეოგრაფიული ლოკაციებით შევამოწმოთ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 გეოგრაფიული ლოკაცია\n",
    "\n",
    "გეოგრაფიული ლოკაციების ცვლადების გასაანალიზებლად, რა თქმა უნდა ყველაზე აზრიანი მათი რუქაზე დატანა იქნება. თუმცა ამას საკმაოდ მძიმე ბიბლიოთეკები აკეთებენ, ამიტომ ჩვენ მარტივი გზით წავიდეთ და გაბნეულობის გრაფიკი დავიხმაროთ.\n",
    "\n",
    "##### გაბნეულობის გრაფიკი\n",
    "გაბნეულობის გრაფიკი - გვიჩვენებს ორი ცვლადის მნიშვნელობებს წერტილებად. ყველაზე ხშირად გამოიყენება ცვლადებს შორის დამოკიდებულების (კორელაციის) შესაფასებლად. თუმცა მას ასევე სეგმენტების გამოსასახადაც იყენებენ. ჩვენ კი შეგვიძლია ზუსტადაც მეორე დანიშნილებით გამოვიყენოთ და გრძედები და განედები x და y ღერძებზე დავიტანოთ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (12, 10))\n",
    "sns.scatterplot(data = df, x = 'pickup_longitude' , y = 'pickup_latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "მოცემული გრაფიკიდან თითქმის შეუძლებელია საერთოდ რამის განსაზღვრა, გარდა ერთისა: ისევე როგორც მგზავრობის ხანგრძლივობაში, გეოგრაფიულ ლოკაციებშიც გვაქვს განცალკევებული მონაცემები. ზემოთ მოყვანილ გრაფიკს თუ დავუჯერებთ ზოგიერთი მგზავრი ტაქსიმ ნიუ იორკიდან რამდენიმე ასეული კილომეტრის დაშორებით აიყვანა, რაც სავარაუდოდ შეცდომაა მონაცემებში.\n",
    "\n",
    "ახლა კი მოდით გრაფკიკის მეტად წაკითხვად ფორმატში მოყვანას შევუდგეთ:\n",
    "* პირველ რიგში გრაფკიკის x და y ღერძები შევზღუდოთ\n",
    "* ასევე სასურველია წერტილებს მეტი გამჭვირვალობა შევძინოთ\n",
    "* და ზომაში შევამციროთ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (12, 10))\n",
    "sns.scatterplot(data = df, x = 'pickup_longitude' , y = 'pickup_latitude', alpha = 0.1, s = 10)\n",
    "plt.xlim((-74.05, -73.75)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად\n",
    "plt.ylim((40.6, 40.9)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "როგორც ხედავთ მხოლოდ ტაქსიში ჩასხდომის წერტილების დასმით ნიუ იორკის რუქა გამოისახა. ცხადად ჩანს, რომ ძირითადი მგზავრობები მანჰეტენზე ხდება, რაც ლოგიკურია. ტაქსით მომსხაურება საკმაოდ ძვირია მანჰეტენი კიდე ქალაქის ყველაზე მდიდარი და საქმიანი უბანია. ქვედა მარჯვენა კუთხეში დატვირთული ნაწილი კი აეროპორტია. ახლა კი იგივეს დავაკვირდეთ კომპანიების ჭრილში თუ დავინახავთ რაიმე განსხვავებას."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (12, 10))\n",
    "sns.scatterplot(data = df[df['vendor_id'] == 1], x = 'pickup_longitude' , \\\n",
    "                y = 'pickup_latitude', alpha = 0.1, s = 10, color='red')\n",
    "plt.xlim((-74.05, -73.75)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად\n",
    "plt.ylim((40.6, 40.9)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (12, 10))\n",
    "sns.scatterplot(data = df[df['vendor_id'] == 2], x = 'pickup_longitude' , \\\n",
    "                y = 'pickup_latitude', alpha = 0.1, s = 10, color='blue')\n",
    "plt.xlim((-74.05, -73.75)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად\n",
    "plt.ylim((40.6, 40.9)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "მოცემული გრაფიკებიდან ჩანს რომ ორივე კომპანია თანაბრად ფარავს მთლიან ქალაქს. თუმცა რამდენიმე აბზაცის წინ ჩვენ ვივარაუდეთ რომ მეორე კომპანია უფრო შორ მონაკვეთებზე მუშაობდა. ისღა დაგვრჩენია ჩასხდომის და დასრულების ლოკაციების შედარებით მეტი მგზავრის ჭრილში შევხედოთ. როგორც ვნახეთ პირველი კომპანია თითქმის არ ემსახურებოდა 5 ან მეტ მგზავრს, შესაბამისად ჩვენც ზუსტად ასეთი პირობით შევამოწმოთ წერტილების სიხშირე."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (12, 10))\n",
    "sns.scatterplot(data = df[df['passenger_count'] >= 5], x = 'pickup_longitude' , \\\n",
    "                y = 'pickup_latitude', alpha = 0.1, s = 10, color='green')\n",
    "plt.xlim((-74.05, -73.75)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად\n",
    "plt.ylim((40.6, 40.9)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (12, 10))\n",
    "sns.scatterplot(data = df[df['passenger_count'] >= 5], x = 'dropoff_longitude' , \\\n",
    "                y = 'dropoff_latitude', alpha = 0.1, s = 10, color='green')\n",
    "plt.xlim((-74.05, -73.75)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად\n",
    "plt.ylim((40.6, 40.9)) #მნიშვნელობები მიღებულია მრავალი იტერაციის შედეგად"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "აქ უკვე ნათლად გამოჩნდა, რომ მგზავრობის დასრულების ლოკაციებში, მეტადაა დატვირთული მეორე კომპანია. ზოგადად ასეთი მონაცემი ბევრი არ არის ჩვენს ცხრილში. თუმცა შეგვიძლია დავასკვნათ, რომ მგზავრების რაოდენობის და კომპანიის კომბინაცია მნიშვნელოვანი ფაქტორი შეიძლება იყოს მოდელირებისას. შესაბამისად მონაცემების სიდიდის მიუხედავად ისინი აუცილებლად უნდა დავტოვოთ მოდელირების პროცესში.\n",
    "\n",
    "რა თქმა უნდა აღნიშნულ ცვლადებზე კიდევ უფრო დეტალური ანალიზის გაკეთებაც შეიძლება, მაგალითად მოვიძიეთ გარე წყარო, რომელიც გრძედებისა და განედების მიხედვით ცერტილებს მიანიჭებს ქალაქის უბნებს და უკვე უბნების ჭრილში გავანალიზოთ მონაცემები. ჩვენ რჩევაც ზუსტად ეს იქნება, მოიძიოთ დამატებითი ინფორმაცია რაც შეიძლება სასარგებლო იყოს იქნება ეს უბნები, ჰაერის ტემპერატურა თუ სხვა რამე."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 მგზავრობის დროები\n",
    "\n",
    "##### Line Chart\n",
    "გრაფიკის ტიპი რომელიც სერიული ტიპის მონაცემებს წარმოაჩენს როგორც უწყვეტი ხაზით დაკავშირებულ მრავალ წერტილს. აღნიშნული ვიზუზალიზაცია ძირითადად გამოიყენება დროზე დამოკიდებული ცვლდებისთის. შესაბამისად ჩვენი დარჩენი ორი ცვლადის (მგზავრრობის დაწყების და დასრულების დროები) გასაანილეზებლად სწორედაც Line chart დაგვჭირდება. \n",
    "\n",
    "დროის ცვლადების კარგად გასაანალიზებლად პირველ რიგში მათი ჩაშვლა დაგვჭირდება, თვეებად, კვირის დღეებად და საათებად."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ეს შეიძლება ითქვას რომ მახასიათებლების შექმნის ნაწილია, თუმცა ამაზე შემდგომ თავში უფრო დეტალურად ვისაუბრებთ\n",
    "\n",
    "df['pickup_month'] = df['pickup_datetime'].dt.month #datetime ფორმატიდან თვის ამოღება\n",
    "df['dropoff_month'] = df['dropoff_datetime'].dt.month #datetime ფორმატიდან თვის ამოღება\n",
    "\n",
    "df['pickup_weekday'] = df['pickup_datetime'].dt.dayofweek #datetime ფორმატიდან კვირის დღის ამოღება\n",
    "df['dropoff_weekday'] = df['dropoff_datetime'].dt.dayofweek #datetime ფორმატიდან კვირის დღის ამოღება\n",
    "\n",
    "df['pickup_hour'] = df['pickup_datetime'].dt.hour #datetime ფორმატიდან საათის ამოღება\n",
    "df['dropoff_hour'] = df['dropoff_datetime'].dt.hour #datetime ფორმატიდან საათის ამოღება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=df, x=\"pickup_hour\", y=\"trip_duration\", ci=None, hue='pickup_weekday', legend='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "გრაფიკზე ვხედავთ მგზავრობის საშუალო ხანგრძლიოვბას კვირის დღეებისა და საათების მიხედვით. მკაფიოდ ჩანს რომ უქმეებზე (5-შაბათი, 6-კვირა) საშუალოდ უფრო სწრაფად გაადგილდება ტაქსი. ყველაზე მაღალი მაჩვენებელი კი სამუშაო დღეებში 10 საათიდან 17 საათამდეა. ასევე ჩანს თუ როგორი გადატვირთულია ქალაქი შაბათს საღამოს საათებში, თუმცა საეჭვოდ გაზრდილია. კიდევ ერთი მკვეთრი უცნაურობა კი სამშაბათს შუაღამეა, რაც დამატებით ჩაძიებას საჭიროებს."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df[(df['pickup_hour'] == 0) & (df['pickup_weekday'] == 1)]['trip_duration'].describe(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df[(df['pickup_hour'] == 22) & (df['pickup_weekday'] == 5)]['trip_duration'].describe(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "როგორც მოსალოდნელი იყო, საშუალოს \"გაფუჭება\" ჩვენი განცალკევებული მონაცემების ბრალი აღმოჩნდა. მოდით ახლიდან დავაკვირდეთ იგივე გრაფიკს, მხოლოდ ისევ 2 საათზე მოვჭრათ მონაცემები როგორც თავის დასაწყისში."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=df[df['trip_duration'] < 7200], x=\"pickup_hour\", y=\"trip_duration\", \\\n",
    "             ci=None, hue='pickup_weekday', legend='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "მგზავრობის ხანგრძლივობის ხანგრძლიოვბის 2 საათზე მოჭრამ, არა მხოლოდ მკვეთრად გამოხატული უცნაურობები გააქრო, არამედ ზოგადად მთელი გრაფიკი უფრო დააგლუვა. \n",
    "\n",
    "ზოგადად მსგავსი ტიპის ოპერაციას განცალკევებული მონაცემების გადაყრას ვუწოდებთ ხოლმე. ის ერთ-ერთი უმნიშნველოვანესი ნაწილია, როდესაც გვსურს როგორც მონაცემების სწორად გაანალიზება ისე მოდელირება. თუმცა ამ პროცესის გარდა კიდევ ბევრი ნაბიჯია გასავლელი იქამდე სანამ მოდელის პირველ დამუშავებულ ვერსიას გავუშვებთ. ამ პროცესების ერთობლიობას მონაცემების მომზადება ეწოდება და იდეურად ის მონაცემების კვლევითი ანალიზის განუყოველი ნაწილია. თუმცა ჩვენ გვურს ეს შემდგომ თავში გავიაროთ, რათა უფრო მეტ დეტალებზე კონცენტრირება შევძლოთ და სიახლეებიც ნაბიჯ-ნაბიჯ ავითვისოთ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
